{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convergence diagnostics\n",
    "\n",
    "`pypsv` uses an MCMC sampler (`numpyro` `NUTS` via `pyMC`). To make sure the results are meaningful, some proxies exist to test whether the sampled ensemble converged to the posterior distribution. `pypsv` comes with a convenience routine to generate a summary table and print some diagnostics. We first load the output from the previous example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "\n",
    "iData = az.from_netcdf('./example_out_akm.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then run the summary calculation and diagnostics routine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypsv.convergence_report import calc_summary_and_print_diagnostics\n",
    "\n",
    "summary = calc_summary_and_print_diagnostics(iData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output indicates that there were no divergences and the chains have mixed well. The tail estimated effective sample sizes suggest a slight auto-correlation in the chains. We can deal with this by thinning the ensemble, as shown in the next example. Additionally, we can look at the marginal energy and the log-posterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 5))\n",
    "\n",
    "az.plot_energy(iData, ax=axs[0])\n",
    "\n",
    "lp = np.array(iData.sample_stats['lp'])\n",
    "n_chains = lp.shape[0]\n",
    "\n",
    "for it in range(4):\n",
    "    axs[1].plot(\n",
    "        np.arange(lp.shape[1]),\n",
    "        lp[it],\n",
    "    )\n",
    "\n",
    "axs[1].set_ylabel('log $p$')\n",
    "axs[1].set_xlabel('$n$ in chain')\n",
    "axs[1].set_xlim(0, lp.shape[1])\n",
    "\n",
    "fig.tight_layout(w_pad=1.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The marginal energy and energy transition distributions (top plot) overlap well, indicating good exploration properties of the sampler. Further, the log-posterior values for the individual chains show no obvious signs of auto-correlation, again indicating good sampling behaviour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional information on convergence diagnostics for MCMC can be found in the [stan docs](https://mc-stan.org/docs/reference-manual/analysis.html) or in *Bayesian Data Analysis* by Gelman et al. (Chapman and Hall, 3rd ed, 2013)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcmc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
